apiVersion: batch/v1
kind: CronJob
metadata:
  name: pg-backup-cron
  namespace: project
spec:
  schedule: "0 0 * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: pg-backup
              # Using Google Cloud SDK image which has gsutil preinstalled
              image: gcr.io/google.com/cloudsdktool/google-cloud-cli:latest
              command:
                - /bin/bash
                - -c
                - |
                  set -e

                  # Install PostgreSQL client
                  apt-get update && apt-get install -y postgresql-client-17

                  # Activate service account
                  gcloud auth activate-service-account --key-file=/secrets/gcs/key.json

                  # Set the project (replace with your actual project ID)
                  gcloud config set project $GCP_PROJECT_ID

                  # Create backup with timestamp
                  BACKUP_FILE="backup-$(date +%Y-%m-%d-%H-%M-%S).sql.gz"
                  echo "Creating backup: $BACKUP_FILE"

                  # Create backup directory
                  mkdir -p /tmp/backups

                  # Perform backup
                  pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" --verbose | gzip > /tmp/backups/$BACKUP_FILE

                  # Upload to GCS using gsutil
                  echo "Uploading to GCS..."
                  gsutil cp /tmp/backups/$BACKUP_FILE gs://$GCS_BUCKET/

                  # Verify upload
                  gsutil ls gs://$GCS_BUCKET/$BACKUP_FILE

                  # Cleanup old backups (keep last 30 days)
                  echo "Cleaning up old backups..."
                  CUTOFF_DATE=$(date -d '30 days ago' +%Y-%m-%d)

                  gsutil ls gs://$GCS_BUCKET/backup-*.sql.gz | while read file; do
                    # Extract date from filename
                    filename=$(basename "$file")
                    if [[ $filename =~ backup-([0-9]{4}-[0-9]{2}-[0-9]{2}) ]]; then
                      file_date="${BASH_REMATCH[1]}"
                      if [[ "$file_date" < "$CUTOFF_DATE" ]]; then
                        echo "Deleting old backup: $file"
                        gsutil rm "$file"
                      fi
                    fi
                  done

                  echo "Backup completed successfully at $(date)"
              env:
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: postgres-secret
                      key: PGPASSWORD
                - name: DB_HOST
                  valueFrom:
                    secretKeyRef:
                      name: postgres-secret
                      key: POSTGRES_HOST
                - name: DB_USER
                  valueFrom:
                    secretKeyRef:
                      name: postgres-secret
                      key: POSTGRES_USER
                - name: DB_NAME
                  valueFrom:
                    secretKeyRef:
                      name: postgres-secret
                      key: POSTGRES_DB
                - name: GCS_BUCKET
                  value: "my-unique-postgres-backup-bucket"
                - name: GCP_PROJECT_ID
                  value: "master-coder-465618-q6"
              volumeMounts:
                - name: gcs-secret
                  mountPath: "/secrets/gcs"
                  readOnly: true
          volumes:
            - name: gcs-secret
              secret:
                secretName: gcs-secret
          restartPolicy: OnFailure
